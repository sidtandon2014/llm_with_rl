{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bdd388-57cb-4c54-9001-93e1e55317d5",
   "metadata": {
    "execution": {
     "execution_failed": "2026-01-21T23:38:50.694Z"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a935969-5ec1-4c07-9b6a-8dd304813d33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:49:12.436255Z",
     "iopub.status.busy": "2026-01-21T23:49:12.435983Z",
     "iopub.status.idle": "2026-01-21T23:49:15.226743Z",
     "shell.execute_reply": "2026-01-21T23:49:15.225156Z",
     "shell.execute_reply.started": "2026-01-21T23:49:12.436231Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._subclasses.fake_tensor' has no attribute 'UnsupportedMutationAliasingException'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GenerationConfig\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SamplingParams\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marg_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EngineArgs\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mentrypoints\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/rl_algos/lib/python3.11/site-packages/vllm/__init__.py:14\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# The environment variables override should be imported before any other\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# modules to ensure that the environment variables are set before any\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# other modules are imported.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01menv_override\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m     16\u001b[39m MODULE_ATTRS = {\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbc_linter_skip\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m._bc_linter:bc_linter_skip\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbc_linter_include\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m._bc_linter:bc_linter_include\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mScoringRequestOutput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m.outputs:ScoringRequestOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     41\u001b[39m }\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typing.TYPE_CHECKING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/rl_algos/lib/python3.11/site-packages/vllm/env_override.py:24\u001b[39m\n\u001b[32m     22\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mTORCHINDUCTOR_COMPILE_THREADS\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# see https://github.com/vllm-project/vllm/issues/10619\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_inductor\u001b[49m.config.compile_threads = \u001b[32m1\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# ===================================================\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# torch 2.9 Inductor PythonWrapperCodegen monkeypatch\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# ===================================================\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# This change monkeypatches memory_plan_reuse in pytorch 2.9.0 to work around\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# a test failure for test_multi_graph_piecewise_compile_outputs_equal.\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# For more context, see https://github.com/pytorch/pytorch/pull/165514.\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmemory_plan_reuse_patched\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/rl_algos/lib/python3.11/site-packages/torch/__init__.py:2686\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m   2683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mTORCH_CUDA_SANITIZER\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m   2684\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcuda\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sanitizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcsan\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2686\u001b[39m     csan.enable_cuda_sanitizer()\n\u001b[32m   2688\u001b[39m \u001b[38;5;66;03m# Populate magic methods on SymInt and SymFloat\u001b[39;00m\n\u001b[32m   2689\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msym_node\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/rl_algos/lib/python3.11/importlib/__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/rl_algos/lib/python3.11/site-packages/torch/_inductor/__init__.py:11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, IO, Literal, Optional, TYPE_CHECKING, Union\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstandalone_compile\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CompiledArtifact  \u001b[38;5;66;03m# noqa: TC001\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InputType\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/rl_algos/lib/python3.11/site-packages/torch/_inductor/standalone_compile.py:12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Literal, Optional, TYPE_CHECKING\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamo_timed\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpp_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize_path_separator\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcudagraph_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BoxedDeviceIndex\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/rl_algos/lib/python3.11/site-packages/torch/_dynamo/__init__.py:13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mTorchDynamo is a Python-level JIT compiler designed to make unmodified PyTorch programs faster.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mTorchDynamo hooks into the frame evaluation API in CPython (PEP 523) to dynamically modify Python\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \u001b[33;03mseamlessly optimize PyTorch programs, including those using modern Python features.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     14\u001b[39m     aot_compile,\n\u001b[32m     15\u001b[39m     config,\n\u001b[32m     16\u001b[39m     convert_frame,\n\u001b[32m     17\u001b[39m     eval_frame,\n\u001b[32m     18\u001b[39m     functional_export,\n\u001b[32m     19\u001b[39m     resume_execution,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/rl_algos/lib/python3.11/site-packages/torch/_dynamo/aot_compile.py:15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprecompile_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PrecompileContext\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Hooks\n\u001b[32m     19\u001b[39m log = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/rl_algos/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcallback\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CallbackTrigger\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/rl_algos/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:53\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ObservedException, TensorifyScalarRestartAnalysis\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracing, TracingContext\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_logging\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstructured\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dump_file\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/envs/rl_algos/lib/python3.11/site-packages/torch/_dynamo/exc.py:425\u001b[39m\n\u001b[32m    416\u001b[39m     tx.exn_vt_stack.clear_current_exception()\n\u001b[32m    419\u001b[39m \u001b[38;5;66;03m# These exceptions are ok to fallback to eager/graph_break.\u001b[39;00m\n\u001b[32m    420\u001b[39m exceptions_allowed_to_be_fallback = (\n\u001b[32m    421\u001b[39m     torch._subclasses.fake_tensor.DataDependentOutputException,\n\u001b[32m    422\u001b[39m     torch._subclasses.fake_tensor.DynamicOutputShapeException,\n\u001b[32m    423\u001b[39m     torch._subclasses.fake_tensor.UnsupportedOperatorException,\n\u001b[32m    424\u001b[39m     torch._subclasses.fake_tensor.UnsupportedFakeTensorException,\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_subclasses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfake_tensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUnsupportedMutationAliasingException\u001b[49m,\n\u001b[32m    426\u001b[39m )\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munimplemented_with_warning\u001b[39m(\n\u001b[32m    430\u001b[39m     e: \u001b[38;5;167;01mException\u001b[39;00m, code: types.CodeType, msg: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m    431\u001b[39m ) -> NoReturn:\n\u001b[32m   (...)\u001b[39m\u001b[32m    437\u001b[39m     \u001b[38;5;66;03m# exception, its ok to fallback to eager but not silently. Here, we can use\u001b[39;00m\n\u001b[32m    438\u001b[39m     \u001b[38;5;66;03m# this function to log the message and the stack trace.\u001b[39;00m\n\u001b[32m    439\u001b[39m     graph_break_msg = format_error_msg_verbose(e, code)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch._subclasses.fake_tensor' has no attribute 'UnsupportedMutationAliasingException'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "from vllm import SamplingParams\n",
    "from vllm.engine.arg_utils import EngineArgs\n",
    "from vllm.entrypoints.llm import LLM\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099f21f-1c6e-47e2-968a-7be76badd086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "def get_dataset(split=\"train\"):\n",
    "    dataset = load_dataset(\"openai/gsm8k\", \"main\", split=split)\n",
    "    QAs = [{'Q':x, 'A':y.split('####')[-1].strip()} for x,y in zip(dataset['question'], dataset['answer'])]\n",
    "    return QAs\n",
    "\n",
    "train_dataset = get_dataset(\"train\")\n",
    "test_dataset = get_dataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce33236f-bfd7-46b1-867e-d474ec1d868f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:37:24.400149Z",
     "iopub.status.busy": "2026-01-21T23:37:24.399898Z",
     "iopub.status.idle": "2026-01-21T23:37:24.435505Z",
     "shell.execute_reply": "2026-01-21T23:37:24.434487Z",
     "shell.execute_reply.started": "2026-01-21T23:37:24.400128Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SamplingParams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m NUM_GEN=\u001b[32m8\u001b[39m\n\u001b[32m      8\u001b[39m MAX_PROMPT_LENGTH=\u001b[32m200\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m sampling_params = \u001b[43mSamplingParams\u001b[49m(n=GROUP_SIZE\n\u001b[32m     11\u001b[39m                                  , temperature=\u001b[32m0.9\u001b[39m\n\u001b[32m     12\u001b[39m                                  , max_tokens=\u001b[32m512\u001b[39m)\n\u001b[32m     14\u001b[39m system_prompt = \u001b[33m\"\"\"\u001b[39m\u001b[33mYou are a helpful assistant. A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33mThe reasoning process and answer are enclosed within <think> </think> and<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'SamplingParams' is not defined"
     ]
    }
   ],
   "source": [
    "GBS = 32\n",
    "MBS=4\n",
    "MAX_SEQ_LEN=256\n",
    "GROUP_SIZE=8\n",
    "\n",
    "\n",
    "NUM_GEN=8\n",
    "MAX_PROMPT_LENGTH=200\n",
    "\n",
    "sampling_params = SamplingParams(n=GROUP_SIZE\n",
    "                                 , temperature=0.9\n",
    "                                 , max_tokens=512)\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful assistant. A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\\\n",
    "The reasoning process and answer are enclosed within <think> </think> and<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>.\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02071c8b-c06e-4102-a229-4bd11134afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "\n",
    "\n",
    "# Set the environment variable to use specific GPUs (e.g., devices 0 and 1)\n",
    "# For a single GPU, use '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "# Configure engine arguments\n",
    "engine_args = EngineArgs(\n",
    "    model=model_name,\n",
    "    dtype=\"bfloat16\",  # Specify the data type: \"auto\", \"half\", \"bfloat16\", \"float\"\n",
    ")\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = LLM(engine_args=engine_args)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "rl_algos",
   "name": "workbench-notebooks.m138",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m138"
  },
  "kernelspec": {
   "display_name": "rl_algos (Local)",
   "language": "python",
   "name": "rl_algos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
