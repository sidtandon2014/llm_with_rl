{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3a9fb6-42c2-4a7b-bb97-0f2edd4aee4a",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4f41a6-e11f-40c6-897f-4d5ed1307f85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:00:28.345669Z",
     "iopub.status.busy": "2026-01-21T23:00:28.345400Z",
     "iopub.status.idle": "2026-01-21T23:00:31.014529Z",
     "shell.execute_reply": "2026-01-21T23:00:31.013316Z",
     "shell.execute_reply.started": "2026-01-21T23:00:28.345647Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rl_algos/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import GenerationConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e4d81-5b55-4c37-9661-639a69e42bc8",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ea3ec2-e435-4195-a916-4ed17647f7db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:00:31.030869Z",
     "iopub.status.busy": "2026-01-21T23:00:31.030256Z",
     "iopub.status.idle": "2026-01-21T23:00:36.877605Z",
     "shell.execute_reply": "2026-01-21T23:00:36.876487Z",
     "shell.execute_reply.started": "2026-01-21T23:00:31.030840Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "ref_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"bfloat16\",\n",
    "    device_map=\"cuda:0\"\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"bfloat16\",\n",
    "    device_map=\"cuda:1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00bcdc7a-3586-4365-a3fc-9ddd75773096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-19T23:38:52.242910Z",
     "iopub.status.busy": "2026-01-19T23:38:52.242566Z",
     "iopub.status.idle": "2026-01-19T23:38:52.246454Z",
     "shell.execute_reply": "2026-01-19T23:38:52.245476Z",
     "shell.execute_reply.started": "2026-01-19T23:38:52.242880Z"
    }
   },
   "outputs": [],
   "source": [
    "# ref_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599b26c9-6c48-4e40-9ceb-3a364c48d11b",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c29eb592-285b-4dd0-8019-ba78dc06402f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:00:36.879024Z",
     "iopub.status.busy": "2026-01-21T23:00:36.878542Z",
     "iopub.status.idle": "2026-01-21T23:00:42.892953Z",
     "shell.execute_reply": "2026-01-21T23:00:42.891942Z",
     "shell.execute_reply.started": "2026-01-21T23:00:36.878999Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "def get_dataset(split=\"train\"):\n",
    "    dataset = load_dataset(\"openai/gsm8k\", \"main\", split=split)\n",
    "    QAs = [{'Q':x, 'A':y.split('####')[-1].strip()} for x,y in zip(dataset['question'], dataset['answer'])]\n",
    "    return QAs\n",
    "\n",
    "train_dataset = get_dataset(\"train\")\n",
    "test_dataset = get_dataset(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c4e499-cf25-4202-baf8-ec4936844777",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97089487-4f45-4842-941d-8afa771d9a68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:00:42.894258Z",
     "iopub.status.busy": "2026-01-21T23:00:42.893782Z",
     "iopub.status.idle": "2026-01-21T23:00:42.898444Z",
     "shell.execute_reply": "2026-01-21T23:00:42.897538Z",
     "shell.execute_reply.started": "2026-01-21T23:00:42.894232Z"
    }
   },
   "outputs": [],
   "source": [
    "GBS = 32\n",
    "MBS=4\n",
    "SEQ_LEN=256\n",
    "GROUPS_SIZE=8\n",
    "\n",
    "\n",
    "NUM_GEN=8\n",
    "MAX_PROMPT_LENGTH=512\n",
    "generation_config = GenerationConfig(\n",
    "            max_new_tokens=512,\n",
    "            do_sample=True, \n",
    "            temperature=0.9, \n",
    "            num_return_sequences=NUM_GEN,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful assistant. A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The Assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\\\n",
    "The reasoning process and answer are enclosed within <think> </think> and<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>.\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3c902c-927b-462d-b7c2-4ae09820d986",
   "metadata": {},
   "source": [
    "## Evaluation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b3f69e9-2cf2-4b3c-807f-ba1c23171e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:00:51.391603Z",
     "iopub.status.busy": "2026-01-21T23:00:51.391271Z",
     "iopub.status.idle": "2026-01-21T23:00:51.398259Z",
     "shell.execute_reply": "2026-01-21T23:00:51.397441Z",
     "shell.execute_reply.started": "2026-01-21T23:00:51.391576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Janetâ€™s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][\"Q\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88dbd2e5-0402-4144-9d9c-23c9714c6d2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:01:23.453687Z",
     "iopub.status.busy": "2026-01-21T23:01:23.453329Z",
     "iopub.status.idle": "2026-01-21T23:01:23.458303Z",
     "shell.execute_reply": "2026-01-21T23:01:23.457450Z",
     "shell.execute_reply.started": "2026-01-21T23:01:23.453659Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = tokenizer.apply_chat_template([\n",
    "                {\"role\":\"system\", \"content\":system_prompt},\n",
    "                {\"role\":\"user\", \"content\":test_dataset[0][\"Q\"]},]\n",
    "                                          ,tokenize=False\n",
    "                                          ,add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dc82d76-a29a-4323-b797-3532317d739f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T23:01:58.735786Z",
     "iopub.status.busy": "2026-01-21T23:01:58.735517Z",
     "iopub.status.idle": "2026-01-21T23:01:58.740713Z",
     "shell.execute_reply": "2026-01-21T23:01:58.739943Z",
     "shell.execute_reply.started": "2026-01-21T23:01:58.735765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize(tmp, return_tensors=\"pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30500634-443c-40ba-bfff-30a57bf4ccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers(dataset):\n",
    "    with torch.inference_mode():\n",
    "        inputs=[]\n",
    "        for question,answer in dataset:\n",
    "            inputs.append(tokenizer.apply_chat_template([\n",
    "                {\"role\":\"system\", \"context\":system_prompt},\n",
    "                {\"role\":\"user\", \"context\":question},]\n",
    "                                          ,tokenize=False\n",
    "                                          ,add_generation_prompt=True))\n",
    "\n",
    "            input_tokens = "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "rl_algos",
   "name": "workbench-notebooks.m138",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m138"
  },
  "kernelspec": {
   "display_name": "rl_algos (Local)",
   "language": "python",
   "name": "rl_algos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
